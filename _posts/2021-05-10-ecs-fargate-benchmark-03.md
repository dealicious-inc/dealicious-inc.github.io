---
layout: page
title: ECS Fargate 성능 측정하기 - 구축부터 Benchmark까지 (하)
writer: 황문주
description: "ECS Fargate를 구성하고 성능을 측정해 봅시다."
tags: [AWS, ECS, Fargate, Benchmark]
thumbnail: 'posts/2020-12-28-ecs-fargate-benchmark-36.png'
---

## ECS Fargate Network Performance

### 테스트 준비 및 설정

네트워크 대역폭 테스트의 목적은 간단합니다. Fargate Task Size별 대역폭을 측정하여 에플리케이션에 적합한 리소스 크기를 파악하고 EC2 인스턴스를 사용할 때와 비교하여 비용 효율성을 높이려는 목적입니다.

네트워크 테스트는 iperf3 툴로 진행되었습니다. Fargate를 서버, 같은 VPC 내에 있는 인스턴스를 클라이언트로 삼아 둘 사이의 네트워크 대역폭을 살펴보겠습니다. 로컬에서 바로 Fargate로 테스트를 진행할 수도 있지만, 로컬 환경의 여러가지 변수(ISP에서 제공하는 인터넷 속도, 내부 공유기의 패킷 제한 등)로 인해  로컬 테스트는 제외하였습니다.

클라이언트로 사용할 EC2 인스턴스는 c5n.18xlarge로 진행할 것입니다. 충분히 여유로운 컴퓨팅 리소스를 부여해서 Fargate와 통신 시에 최대 성능을 보장하기 위해서 입니다. 특히 기존 c5보다 네트워크 대역폭이 더욱 강화된 n타입 인스턴스를 사용해서 대역폭을 상한선을 끌어 올려 보았습니다. Fargate Task의 CPU와 Memory는 아래 표와 같이 설정할 수 있습니다.

![](/assets/image/posts/2020-12-28-ecs-fargate-benchmark-34.png)

이 중에서 각 CPU 값 별로 두개의 memory를 지정하여 10개의 시나리오에 대한 테스트를 진행할텐데요, 추가로 iperf3의 --reverse 옵션을 통해서 서버와 클라이언트의 송/수신을 바꿔 총 20개의 테스트 결과를 도출해 보겠습니다. 전송 시간은 기본값이 10초이지만, TCP의 Slow Start와 초기의 최고 성능 값을 제외하기 위해 --omit 옵션으로 처음 10초를 제외하겠습니다. 총 측정 시간은 60초 동안 수행되며, --parallel 옵션을 2로 부여하여 2개의 TCP stream 의 측정값을 합산합니다.

### 결과

#### Bandwidth test result

CPU value | Memory value | Bandwidth(Gbit/s) (ec2 -> Fargate) | Bandwidth(Gbit/s) (Fargate -> ec2) | Price(USD/hour)
---|---:|---:|---:|---:
256(0.25vCPU) | 0.5GB | 2.38 | 4.70 | 0.014195
256(0.25vCPU) | 2GB | 2.50 | 4.79 | 0.02186
512(0.5vCPU) | 1GB | 4.42 | 4.79 | 0.02839
512(0.5vCPU) | 4GB | 4.71 | 4.79 | 0.04372
1024(1vCPU) | 2GB | 9.17 | 9.19 | 0.05678
1024(1vCPU) | 8GB | 8.46 | 9.19 | 0.08744
2048(2vCPU) | 4GB | 9.03 | 9.25 | 0.11356
2048(2vCPU) | 16GB | 9.51 | 9.58 | 0.017488
4096(4vCPU) | 8GB | 9.36 | 9.58 | 0.22712
4096(4vCPU) | 30GB | 9.51 | 9.58 | 0.33954

위의 결과 표를 차트로 나타내 보았습니다.

![](/assets/image/posts/2020-12-28-ecs-fargate-benchmark-36.png)

특이한 점이 보이시나요? 우선 Fargate도 m5.large ~ m5.4xlarge 까지 최대 네트워크 성능은 비슷하게 보여주는 것으로 나타났습니다. (Up to 10 Gbps.) 또한 메모리의 성능은 네트워크 대역폭과 비례하지 않는 것도 알 수 있는데요. 주로 CPU가 늘어날 때마다 대역폭이 상승 하였으며, 2vCPU부터는 네트워크 대역폭의 큰 상승은 없는 것으로 확인됐습니다.

그리고 0.25 vCPU 를 사용하는 경우 Fargate로 들어오는 트래픽 보다 Fargate에서 나가는 트래픽이 두 배 가까이 높은 것으로 관측되었습니다.

따라서 위의 대역폭을 참고하여 서비스 배포 시에 몇개의 태스크를 생성할 것인지 어림잡아 짐작이 가능할 것으로 보입니다. 보통 네트워크 대역폭이 Inbound/outbound를 합친 성능을 의미하므로 전송량에 따라 적절히 태스크 수를 예상할 수 있겠습니다.

또한 1vCPU / 2GB Memory 의 Fargate만 사용해도 최대치의 90% 가까운 네트워크 성능을 내므로 리소스의 가격대비 성능은 1vCPU / 2GB Memory 선택이 가장 좋다고 볼 수 있겠네요.

## ECS Fargate Memory Performance

네트워크 대역폭까지 실습해 보신 분이라면 Dockerfile에 메모리 측정 관련 명령이 없다는 것을 아셨을 것입니다. Memory 성능 측정 툴은 sysbench를 사용했지만 자세한 방법은 여기서는 밝히지 않을 테니 한 번 가능한 방법을 생각해 보셔도 좋을 것 같습니다. 정답은 없겠지만, 성공하신 방법이 있다면 댓글로 공유해 주세요! 독자 분들에게도 많은 도움이 되지 않을까 싶습니다.

메모리 성능을 테스트한 결과는 아래와 같습니다.

#### 읽기 성능

CPU value | Memory value | MiB transferred(MiB/sec) | Execution Time (sec)
---|---:|---:|---: 
256(0.25vCPU) | 0.5GB | 10240.00(5471.94) | 1.8657
256(0.25vCPU) | 2GB | 10240.00(5475.06) | 1.8634
512(0.5vCPU) | 1GB | 10240.00(11355.77) | 0.8949
512(0.5vCPU) | 4GB | 10240.00(11554.61) | 0.8811
1024(1vCPU) | 2GB | 10240.00(16903.07) | 0.5841
1024(1vCPU) | 8GB | 10240.00(17637.63) | 0.5589
2048(2vCPU) | 4GB | 10240.00(17037.34) | 0.5988
2048(2vCPU) | 16GB | 10240.00(17003.24) | 0.5809
4096(4vCPU) | 8GB | 10240.00(17112.24) | 0.5766
4096(4vCPU) | 30GB | 10240.00(17344.97) | 0.5690

#### 쓰기 성능

CPU value | Memory value | MiB transferred(MiB/sec) | Execution Time (sec)
---|---:|---:|---: 
256(0.25vCPU) | 0.5GB | 10240.00(3901.48) | 2.6160
256(0.25vCPU) | 2GB | 10240.00(4015.99) | 2.4675
512(0.5vCPU) | 1GB | 10240.00(7977.19) | 1.2770
512(0.5vCPU) | 4GB | 10240.00(8160.14) | 1.2498
1024(1vCPU) | 2GB | 10240.00(11969.14) | 0.8317
1024(1vCPU) | 8GB | 10240.00(12909.14) | 0.7706
2048(2vCPU) | 4GB | 10240.00(12699.87) | 0.7834
2048(2vCPU) | 16GB | 10240.00(12959.62) | 0.7680
4096(4vCPU) | 8GB | 10240.00(13011.95) | 0.7649
4096(4vCPU) | 30GB | 10240.00(12935.61) | 0.7693

위 표의 결과를 차트로 나타내보면 아래와 같습니다.

![](/assets/image/posts/2020-12-28-ecs-fargate-benchmark-37.png)

![](/assets/image/posts/2020-12-28-ecs-fargate-benchmark-38.png)

CPU value가 1024부터는 성능이 크게 증가하지 않는 모습을 관측할 수 있습니다. 메모리 사이즈도 네트워크 성능과 비슷하게 성능과는 큰 관련이 없는 것으로 보이네요.

## 글을 마치며

기존 EC2에 서비스를 올려 사용하는 방식에서, 이제 컨테이너를 통해 서비스를 제공하는 케이스가 계속 늘어나고 있습니다. EC2는 비교적 벤치마크 자료를 쉽게 구할 수 있었는데, Fargate는 많이 찾아 볼 수 없어서 이번 블로그를 작성하게 되었는데요. 처음 기대하던 성능이 나오지는 않은 것 같습니다. 아무래도 Multitenancy 방식으로 Fargate를 사용했기 때문일 가능성도 있을 것 같구요. 그래도 멀티 태스크 환경을 전제로 프로덕션을 배포하는 경우가 많기 때문에 적절한 Task size를 활용하시면 될 것 같습니다.
